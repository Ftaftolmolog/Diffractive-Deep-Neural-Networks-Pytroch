{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.layers import Layer,Lambda,InputLayer\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import cvnn.layers as complex_layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall tensorflow\n",
    "# pip install tensorflow==2.9.0 cvnn tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor((1+0j), shape=(), dtype=complex64)\n",
      "tf.Tensor((0.5403023+0.841471j), shape=(), dtype=complex64)\n",
      "tf.Tensor((2.7182817+0j), shape=(), dtype=complex64)\n",
      "tf.Tensor((0.5403023+0.841471j), shape=(), dtype=complex64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 00:50:57.692249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:57.700781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:57.701013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:57.702018: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-27 00:50:57.702514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:57.702734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:57.702918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:58.441976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:58.442249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:58.442420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 00:50:58.442578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12231 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:10:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(1.)\n",
    "casted = tf.cast(v,dtype=tf.complex64)\n",
    "print(casted)\n",
    "\n",
    "print(tf.math.exp(1j*tf.cast(v,dtype=tf.complex64)))\n",
    "print(tf.math.exp(tf.cast(v,dtype=tf.complex64)))\n",
    "print(tf.complex(tf.cos(v),tf.sin(v)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 200\n",
    "BUFFER_SIZE = 5000\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 1\n",
    "\n",
    "# Define the traning parameters\n",
    "keep_training = False\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "\n",
    "# load the dataset\n",
    "datasets, info = tfds.load(name='fashion_mnist', with_info=True, as_supervised=True, data_dir='./data')\n",
    "\n",
    "fashion_mnist_train, fashion_mnist_test = datasets['train'], datasets['test']\n",
    "\n",
    "num_train = info.splits['train'].num_examples\n",
    "num_test = info.splits['test'].num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Define phase object ( Preprocess the images with up-sampling )\n",
    "1. Load image that serves as phase object  \n",
    "\n",
    "2. Image is 28x28 pixels, and is padded to 200x200 pixels  with 0's  \n",
    "\n",
    "3. Phase Image = exp(2$\\pi$ i * Padded Image)\n",
    "\n",
    "The digital image is encoded in phasor form, with an uniform amplitude and different phase angle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    label = tf.one_hot(tf.cast(label, tf.int32), 10)   # convert the label to categorial, or one-hot coded\n",
    "    \n",
    "    up_sampling_size = int(1*size)\n",
    "    padding_size = (size - up_sampling_size)//2\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Step1: upsample the image to 120x120\n",
    "    up_sampling_image = tf.image.resize(image,\n",
    "                                        size=[up_sampling_size,up_sampling_size],\n",
    "                                        method='nearest')\n",
    "    up_sampling_image = up_sampling_image / 255.0\n",
    "    # Step2: get the phase object\n",
    "    phase_image = tf.math.exp(2*np.pi*1j*tf.cast(up_sampling_image,dtype=tf.complex64))\n",
    "    # Step3: pad the phase object to 200x200 with 0s\n",
    "    zero_padded_image = tf.pad(phase_image,\n",
    "                                paddings=[[padding_size,padding_size],[padding_size,padding_size],[0,0]],\n",
    "                                mode=\"CONSTANT\",constant_values=0)\n",
    "        \n",
    "    return tf.cast(zero_padded_image, dtype=tf.complex64), label\n",
    "    \n",
    "train_dataset = fashion_mnist_train.map(preprocess).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = fashion_mnist_test.map(preprocess).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice:\n",
    "For ___tf.pad()___,  paddings中的第一个[40,40]表示的是垂直方向上的填充，第一个40表示的是向上的填充行数，第二个40表示的是向下的填充行数。第二个[40,40]表示的水平方向上的填充，第一个40表示的向左的填充行数，第二个40表示的是向右的填充行数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Build the Diffraction layer using Angular Spectrum method\n",
    "\n",
    "### Angular Spectrum Propagation\n",
    "$$U_1(x,y) =\\mathcal{F}^{-1}[\\mathcal{F} U_0(x,y)\\mathcal{F}h(x,y)]$$\n",
    "\n",
    "$$U_1(x,y) =\\mathcal{F}^{-1}[\\mathcal{F} U_0(x,y) H(f_x,f_y)]$$\n",
    "\n",
    "\n",
    "This can be described using Fourier transforms.The first Fourier transform decomposes the initial field into plane waves. To propagate the plane waves, we multiply each wave by a complex phase factor, and then we take the inverse Fourier transform to add all the propagated plane waves back together.\n",
    "\n",
    "To implement Angular spectrum propagation, the Fouier transform of the initial field is first multiplied with the phase factor $$H=e^{ik_zz}$$, where $k_z$is a function of the spatial frequencies $$k_z=\\sqrt{k^2-k_x^2-k_y}$$where $$  k = \\frac{2\\pi}{\\lambda}$$ and $k_x$ and $k_y$ are related to the spatial frequencies $f_x$ and $f_y$ by a factor of $2\\pi$ $$k_{x,y} = 2\\pi f_{x,y}$$\n",
    "\n",
    "Hence the complex exponential can be written in terms of the Fourier coordinates $f_x$ and $f_y$, that is \n",
    "\n",
    "$$H=e^{ik_zz},k_z = 2\\pi \\sqrt{\\frac{1}{\\lambda}-f_x-f_y}$$\n",
    "\n",
    "Descretized spatial freqnency $f_x = k*\\Delta f = \\frac{k}{N \\Delta x}$  \n",
    "Interval between the spatial frequencies $\\Delta f = \\frac{1}{N \\Delta x}=\\frac{1}{L}$,where $L$ denotes the field of view in object space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffraction_Layer(Layer):\n",
    "    def __init__(self, units =200):\n",
    "        '''Initialize the diffraction layer attributes'''\n",
    "        super(Diffraction_Layer, self).__init__()\n",
    "        self.units = units\n",
    "        self.Nx = units              # Nx is the dimension of the grid\n",
    "        # self.L = 0.08              # source and observation plane side length, field of view\n",
    "        self.dx = 2e-6\n",
    "        self.lam = 7.5e-6          # wavelength of the optical wave\n",
    "        self.z = 3e-2                # distance of propagation(the distance bewteen two layers)\n",
    "   \n",
    "    def build(self, input_shape):\n",
    "        '''Create the state of the layer (weights)'''\n",
    "        phase_init = tf.random_normal_initializer()\n",
    "        self.phase = tf.Variable(name= \"phase\",\n",
    "                                initial_value=phase_init(shape=(self.units,self.units), dtype='float32'),\n",
    "                                trainable=True)\n",
    "                                # constraint=lambda t: 2*np.pi*tf.math.sigmoid(t))\n",
    "        # To help with the 3D-printing and fabrication of the D2NN design, \n",
    "        # a sigmoid function was used to constrain the phase value of each neuron\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        '''Define the computation'''\n",
    "        def angular_spectrum_propagator(E, z = self.z, lam = self.lam):\n",
    "            # compute angular spectrum\n",
    "            fft_c = tf.signal.fft2d(E)\n",
    "            c = tf.signal.fftshift(fft_c)\n",
    "\n",
    "            fx = np.fft.fftshift(np.fft.fftfreq(self.Nx, d = self.dx))\n",
    "            fxx, fyy = np.meshgrid(fx, fx)\n",
    "            argument = (2 * np.pi)**2 * ((1. / lam) ** 2 - fxx ** 2 - fyy ** 2)\n",
    "\n",
    "           #Calculate the propagating and the evanescent (complex) modes\n",
    "            tmp = np.sqrt(np.abs(argument))\n",
    "            kz = np.where(argument >= 0, tmp, 1j*tmp)\n",
    "\n",
    "            # propagate the angular spectrum a distance z\n",
    "            E = tf.signal.ifft2d(tf.signal.ifftshift(c * np.exp(1j * kz * z)))\n",
    "            return E\n",
    "        return tf.multiply(angular_spectrum_propagator(inputs),tf.math.exp(1j*tf.cast(self.phase,dtype=tf.complex64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Notice\n",
    "For ___tf.cast()___: In case of casting from real types to complex types(complex64), the imaginary part of the returned value is set to 0.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Propogation(Layer):\n",
    "    def __init__(self, units =200):\n",
    "        '''Initialize the diffraction layer attributes'''\n",
    "        super(Propogation, self).__init__()\n",
    "        self.units = units\n",
    "        self.Nx = units              # Nx is the dimension of the grid\n",
    "        self.dx = 2e-6\n",
    "        self.lam = 7.5e-6            # wavelength of the optical wave\n",
    "        self.z = 1e-2                # distance of propagation(the distance bewteen last layer and the detector)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        '''Define the computation'''\n",
    "        def angular_spectrum_propagator(E, z = self.z, lam = self.lam):\n",
    "            # compute angular spectrum\n",
    "            fft_c = tf.signal.fft2d(E)\n",
    "            c = tf.signal.fftshift(fft_c)\n",
    "\n",
    "            fx = np.fft.fftshift(np.fft.fftfreq(self.Nx, d = self.dx))\n",
    "            fxx, fyy = np.meshgrid(fx, fx)\n",
    "            argument = (2 * np.pi)**2 * ((1. / lam) ** 2 - fxx ** 2 - fyy ** 2)\n",
    "\n",
    "           #Calculate the propagating and the evanescent (complex) modes\n",
    "            tmp = np.sqrt(np.abs(argument))\n",
    "            kz = np.where(argument >= 0, tmp, 1j*tmp)\n",
    "\n",
    "            # propagate the angular spectrum a distance z\n",
    "            E = tf.signal.ifft2d(tf.signal.ifftshift(c * np.exp(1j * kz * z))) # phase是加还是减\n",
    "            return E\n",
    "        return angular_spectrum_propagator(inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(Layer):\n",
    "    def __init__(self, units=200):\n",
    "        '''Initialize the instance attributes'''\n",
    "        super(Detector, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        ''' Converts output to one hot form\n",
    "        Applies softmax'''\n",
    "        \n",
    "        def rang(arr,shape,size=size,base = 512):\n",
    "            x0 = shape[0] * size // base\n",
    "            y0 = shape[2] * size // base\n",
    "            delta = (shape[1]-shape[0])* size // base\n",
    "            return arr[x0:x0+delta,y0:y0+delta]\n",
    "        \n",
    "        def reduce_mean(tf_):\n",
    "            return tf.reduce_mean(tf_)\n",
    "        \n",
    "        def _ten_regions(a):\n",
    "            return tf.map_fn(reduce_mean,tf.convert_to_tensor([\n",
    "                rang(a,(120,170,120,170)),\n",
    "                rang(a,(120,170,240,290)),\n",
    "                rang(a,(120,170,360,410)),\n",
    "                rang(a,(220,270,120,170)),\n",
    "                rang(a,(220,270,200,250)),\n",
    "                rang(a,(220,270,280,330)),\n",
    "                rang(a,(220,270,360,410)),\n",
    "                rang(a,(320,370,120,170)),\n",
    "                rang(a,(320,370,240,290)),\n",
    "                rang(a,(320,370,360,410))\n",
    "            ]))\n",
    "        \n",
    "        def ten_regions(logits):\n",
    "            return tf.map_fn(_ten_regions,tf.abs(logits),dtype=tf.float32)\n",
    "\n",
    "        return tf.square(ten_regions(tf.abs(inputs))) # logits_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_label,logits_abs):\n",
    "    return tf.reduce_mean(tf.square(logits_abs-y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /environment/miniconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /environment/miniconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (ComplexInput)      [(None, 200, 200)]        0         \n",
      "                                                                 \n",
      " diffraction__layer (Diffrac  (None, 200, 200)         40000     \n",
      " tion_Layer)                                                     \n",
      "                                                                 \n",
      " diffraction__layer_1 (Diffr  (None, 200, 200)         40000     \n",
      " action_Layer)                                                   \n",
      "                                                                 \n",
      " diffraction__layer_2 (Diffr  (None, 200, 200)         40000     \n",
      " action_Layer)                                                   \n",
      "                                                                 \n",
      " diffraction__layer_3 (Diffr  (None, 200, 200)         40000     \n",
      " action_Layer)                                                   \n",
      "                                                                 \n",
      " diffraction__layer_4 (Diffr  (None, 200, 200)         40000     \n",
      " action_Layer)                                                   \n",
      "                                                                 \n",
      " propogation (Propogation)   (None, 200, 200)          0         \n",
      "                                                                 \n",
      " detector (Detector)         (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,000\n",
      "Trainable params: 200,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_D2NN_model():\n",
    "    inputs = complex_layers.complex_input(shape=(size,size))\n",
    "    h1 = Diffraction_Layer(size)(inputs)\n",
    "    h2 = Diffraction_Layer(size)(h1)\n",
    "    h3 = Diffraction_Layer(size)(h2)\n",
    "    h4 = Diffraction_Layer(size)(h3)\n",
    "    h5 = Diffraction_Layer(size)(h4)\n",
    "    propogation = Propogation(size)(h5)\n",
    "    out = Detector()(propogation)\n",
    "    return tf.keras.Model(inputs, out)\n",
    "\n",
    "\n",
    "D2NN = get_D2NN_model()\n",
    "\n",
    "D2NN.summary()\n",
    "# plot_model(D2NN, show_shapes=True, show_layer_names=True, to_file='D2NN-model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 320s 336ms/step - loss: 0.0811 - accuracy: 0.6440 - val_loss: 0.0479 - val_accuracy: 0.7764\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 292s 311ms/step - loss: 0.0431 - accuracy: 0.7981 - val_loss: 0.0412 - val_accuracy: 0.7941\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.8134"
     ]
    }
   ],
   "source": [
    "if keep_training:\n",
    "    D2NN.load_weights('./Training_results/D2NN_MODEL.63-7.3470')\n",
    "\n",
    "D2NN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "             loss=loss_function,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "checkpoint_path = './Training_results/D2NN_MODEL.{epoch}-{val_loss:.4f}'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                             save_weights_only=True,\n",
    "                             sace_freq='epoch')\n",
    "\n",
    "history = D2NN.fit(train_dataset,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_dataset,\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  num   | dataset|type  |dx  |lam |z|accuracy|\n",
    "|  ----  | ----  | ----  | ----  | ----  | ----  | ----  |\n",
    "|  1 | fminst|amplitude  | 2e-6  |7.5e-6  |0.01|73%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting weights from model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(D2NN.layers)\n",
    "# print(D2NN.layers[1].weights)\n",
    "# print(D2NN.layers[2].get_weights()) # get the numpy arrays for the parameters of the layer\n",
    "# print(D2NN.get_layer('diffraction__layer_1').phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
